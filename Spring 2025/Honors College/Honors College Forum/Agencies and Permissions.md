## Permission: 
I give myself permission to:
- not be afraid of judgment by others
- think and speak up about sensitive topics with right intentions 
- develop new notions and ideas while learning from others

---

Giant Smartphones and Viagra

>In her new book [_Invisible Women_](https://www.amazon.com/Invisible-Women-Data-World-Designed/dp/1419729071), Criado Perez examines different elements of the modern world that appear to be designed with less consideration for women: Transportation systems, medical devices and treatments, tax structures, consumer products, even the smartphones and voice-recognition technologies we use every day. The 321-page book is a rapid-fire delivery of data sets, making it more of an academic tome than a light and hopeful read to take with you on summer vacation. But despite the occasional meandering, _Invisible Women_ often arrives right back at the same seemingly inevitable conclusion: There exists a real gender data gap that is “both a cause and a consequence of the type of unthinking that conceives of humanity as almost exclusively male.”

>**LG:** Can you talk specifically about the technology devices you highlight in the book, and how biased data sets have informed biased design? I always think about giant smartphones, because as a reviewer I often note that they just don’t fit in my hands all that well. But then in marketing, the companies might use professional athletes with giant hands holding the phones, so of course it seems small in comparison.

>**CCP:** The category of smartphones is a massive bugbear of mine because I actually got RSI [repetitive strain injury] from an iPhone 6. And I now am stuck with an iPhone SE which I can’t upgrade. The only small phone they had, [they discontinued](https://www.wired.com/story/goodbye-iphone-se-small-phones/), and it’s the only one that fits my hand. It’s incredibly frustrating. And then later when [Apple] introduced Siri, you could use it to [find a viagra supplier but not an abortion clinic](https://bits.blogs.nytimes.com/2011/11/30/apple-says-siris-abortion-answers-are-a-glitch/). So there’s all sorts of examples like that, where there’s not as much thought being put into, you know—female customers exist. Another example is VR headsets being too big.

>Criado Perez's new book [_Invisible Women_](https://www.amazon.com/Invisible-Women-Data-World-Designed/dp/1419729071) is out now. Abrams Books

>But to me the most worrying examples are about algorithms rather than hardware. Because with hardware, it’s kind of easy to see how it is affecting us or not fitting us, and so it’s relatively easy to fix. What’s more concerning to me are algorithms being trained on highly biased male data sets, and the way these algorithms are being introduced in all sorts of areas of our lives. There doesn’t seem to be much understanding amongst the people who are coding these algorithms about the issues with the data they are training them on. That goes from voice recognition systems that don’t recognize female voices, to online dictionaries, to algorithms deciding whether a certain CV will ever reach human eyes.