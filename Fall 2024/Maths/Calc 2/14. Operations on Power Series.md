The General Idea, is that since Power Series are just polynomials for infinite terms, every operation valid on a polynomial is valid on a power series.

### Add & Subtract 
- $f(x) = 1 + 2x^{2} + 4x^{4} + 8x^{6} + \dots$
- $g(x) = 3x^{2} - x^{4} + \frac{1}{3} x^{6} - \dots$
$\implies f(x) + g(x) = 1 + 5x^{2} + 3x^{4} + \frac{25}{3}x^{6} + \dots$

But that would hold true also for the Summation ($\sum$) notation 
$f(x) = \sum^{\infty}_{n=0} 2^{n}x^{2n} = 1 + \sum^{\infty}_{n=1} 2^{n}x^{2n}$
$g(x) = \sum^{\infty}_{n=1} \frac{(-1)^{n+1} x^{2n}}{3^{n-2}}$

Note: you can only add like terms and series with same bounds.

Hence, 
$f(x)+g(x) = 1 + \sum^{\infty}_{n=1} 2^{n}x^{2n} +  \sum^{\infty}_{n=1} \frac{(-1)^{n+1} x^{2n}}{3^{n-2}} = 1 + \sum^{\infty}_{n=1} \left(2^{n} + \frac{(-1)^{n+1}}{3^{n-2}}\right)\cdot  x^{2n}$

### Multiplying 
Find the first 3 non zero terms of $f(x)g(x)$
$f(x)g(x) = (1 + 2x^{2} + 4x^{4} + 8x^{6} + \dots)(3x^{2} - x^{4} + \frac{1}{3} x^{6} - \dots)$
Looking at sample space of first 3 terms from both series,
$f(x)g(x) = 3x^{2} + 5x^{4} + \frac{31}{3}x^{6} + \dots$ (higher order terms)

$(\sum^{\infty}_{n=0} a_{n}x^{n})(\sum^{\infty}_{n=0} b_{n}x^{n})= \sum^{\infty}_{n=0} (\sum^{\infty}_{k=0}a_{k}b_{n-k})x^{n}$

### Substitution 
$f(x) = \sum^{\infty}_{n=0} a_{n}x^{n}$ for all $|x| < \mathbb{R}$

then $f(g(x)) = \sum^{\infty}_{n=0} a_{n}(g(x))^{n}$
for all $x$ with $|g(x)|<R$

### Differentiation and Integration 
Differentiation and integration maintain linearity.
(Derivative of a sum of parts is sum of derivative of parts. I.e. Derivative and Integral are operative functions)

$\frac{d}{dx} (\sum^{\infty}_{n=0} a_{n}x^{n})$ = $\sum^{\infty}_{n=0} \frac{d}{dx}a_{n}x^{n}$

I.e. To differentiate a Power series, you simply differentiate Each term as you regularly would and then add that derivate.

NOTE:
When taking the derivate of a power series, the IOC of the derivate is the same as that of the original except possibly losing the endpoints. Because of a new factor of $n$ for each term, the function may diverge for the bounds.

##### Example 
- $\frac{1}{1+x^{2}} = \frac{1}{1-(-x^{2})} = \sum^{\infty}_{n=0} (-x^{2})^{n} = \sum^{\infty}_{n=0} (-1)^{n}x^{2n}$    
Here, IOC is $(-1,1)$, $R=1$
Integrating both sides,
$arctan(x) = \sum^{\infty}_{n=0} \frac{(-1)^{n}x^{2n+1}}{2n+1} + C$

Because you want the value the converge at the center of convergence, $arctan(0) = \sum^{\infty}_{n=0} \frac{(-1)^{n}0^{2n+1}}{2n+1} + C = C = 0$
So by evaluating the series' derivate, evaluate at the center of convergence.
Note, Here, it gains the endpoints here (just like derivatives would lose endpoints). (Check endpoints)


#cheesy 
A power series is defined for all Elements in the Domain of a number. The reason some radii of convergent may NOT span the entire domain at times is because few functions are not defined for all complex space.

That's the key idea! COMPLEX NUMBERS!
![[Maths/Calc 2/attachments/Drawing 24-11-11-06-38-07]]
The radius of convergence is the radius around a center of convergence around which our function $f(x)$ is defined for values within that radius IN THE COMPLEX PLAIN.

A function that is defined for the entire complex plain has infinite radius of convergence.

The power series representation of a function Does NOT match the function, i.e. the radius of converge is finite for a function and is equal to to furthest distance from the origin UNTIL WHICH THE FUNCTION IS DEFINED FOR THE COMPLEX SPACE.

---
But what is this power series representation?

## Taylor Series 

Taylor series is just the power series representation of ANY function around a particular center of convergence.

The major problem is, how to find the coefficients of all powers of $x$?

- Goal: 
	Given $f(x)$, find a power series that converges to $f(x)$ on some interval.

Suppose $f(x) = \sum^{\infty}_{n=0} c_{n} (x-b)^{n} = c_{0} + c_{1}(x-b)+c_{2}(x-b)^{2} \dots$ converges when $x=b$

How to find $c_{n}$

$f(b) = c_{0}$ since all higher order terms drop to $0$

What about the higher order terms?
We somehow want to decrease the order of different terms so that we can have the same trick of higher order terms dropping to zero.

$f'(x) = c_{1} + 2c_{2}(x-b) + 3c_{3}(x-b)^{2} \dots$
$\implies f'(b) = c_{1}$

Ahaa! We can play the same trick 
$f''(x) = 2c_{2} + 3 \cdot 2 c_{3}(x-b) + \dots$
$\implies f''(b) = 2c_{2} \implies c_{2} = f''\frac{b}{2}$

Hence, $\displaystyle c_{n} = \frac{f^{(n)}b}{n!}$

All right, that means we can use this in our power series representation of our number.
We have... Taylor Series!

#def 
Suppose $f(x)$ is indefinitely differentiable on some interval, and let $b$ be a point in the interval.
Then, the **Taylor Series** for $f(x)$ centered at $x=b$ is $$\sum^{\infty}_{n=0} \frac{f^{n}b}{n!}(x-b)^{n}$$
If $b=0$, we call the series **MacLaurin Series** of $f(x)$.

Taylor series is a power series representation ($\sum c_{n}x^{n}$) of a function where $c_{n} = \frac{f^{(n)}b}{n!}$.
---

#### MacLaurin Series 

1. Find the MacLaurin Series for $f(x) = e^{x}$

- $n=0$:
$f^{n}(x) = e^{x}$
$f^{(n)}(0)=1$
$c_{n} = \frac{f^{n}0}{n!} = \frac{1}{0!}$

- $n=0$:
$f^{n}(x) = e^{x}$
$f^{(n)}(0)=1$
$c_{n} = \frac{f^{n}0}{n!} = \frac{1}{1!}$

- $n=0$:
$f^{n}(x) = e^{x}$
$f^{(n)}(0)=1$
$c_{n} = \frac{f^{n}0}{n!} = \frac{1}{2!}$

- $n=0$:
$f^{n}(x) = e^{x}$
$f^{(n)}(0)=1$
$c_{n} = \frac{f^{n}0}{n!} = \frac{1}{3!}$

Hence, looking at that pattern, $e^{x} = \sum^{\infty}_{n=0} \frac{x^{n}}{n!}$

---
#cheesy 
Taylor Series is generated by the properties of how a function's slopes behave around particular values. The power series, in essence, captures the behavior around a point propagating with a polynomial growth.
Functions like $\cases{e^{\frac{-1}{x^{2}}} \quad x \neq 0 \\0 \quad x = 0}$
just have the function value decaying to $0$ too quickly (exponentially) that the Power series can not capture the propagation fast enough. The power series representation of this function would just be $f(x)=0$ which obviously is not true. 
So the Taylor Series, generated by the differentiable properties of a function may converge to a particular value for all numbers you plug in HOWEVER, that does NOT garuntee that it is the same as the function that generated it. What garuntees is that the Error term of a function goes to zero, for growing $n$. (kind of like is the Propogation fast enough.) 