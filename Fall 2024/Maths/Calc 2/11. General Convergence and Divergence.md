So far, we've considered the convergence patterns of series that are always positive and always negative.

# What if terms have both positive and negative values?

Example:

$\sum^{\infty}_{n=1} \frac{(-1)^{n+1}}{n^{2}} = 1 - \frac{1}{4} + \frac{1}{9} - \frac{1}{16} \dots$

- $\sum a_{n}$ should converge easily since terms are getting smaller and also cancelling out and are not growing forever.

It's often harder to show that though!

---
## Absolute Convergence Test
#def We say that an infinite series $\sum^{\infty}_{n=k} a_{n}$ is absolutely convergent if $\sum^{\infty}_{n=k} |a_{n}|$ converges.

i.e. $1 - \frac{1}{4} + \frac{1}{9} - \frac{1}{16} \dots$ would always be less than $1 + \frac{1}{4} + \frac{1}{9} + \frac{1}{16} \dots$ since the terms are cancelling out.

Hence, if The sum of the absolute value converges then certainly the sum of alternative positive and negative values converge.

In general, you can prove this as:
Assume $\sum^{\infty}_{n=k} |a_{n}|$ converges. 
Since this converges, a certain subsection of the series would be finite.

Grouping all the positive terms and all the negative terms in a different series $S_{p}$ & $S_{n}$ would also be finite. Hence, the sum/difference of two finite numbers would be another finite value.

(more rigorous proof... $0 \leq a_{n} + |a_{n}| \leq 2 |a_{n}| \space \forall \space n$
since sum of $|a_{n}|$ converges, that of $2|a_{n}|$ would also converge. Hence, the sum of $a_{n}$ must also converge.)

Note:
It is not ALWAYS true for all absolute series to converge.
for example $\sum \frac{(-1)^{n}}{n}$ converges but $\sum |a_{n}| = \sum \frac{1}{n}$ in this case. Which doesn't converge.
So the sum of absolute values may not converge, yet the series may converge. But if the sum of absolute values converges, that we know as a matter of fact! That the series converges.

---
Few other tools under our sleeves
# Ratio Test 
#theorem Let $\sum^{\infty}_{n=k} a_{n}$ be an infinite series and let $L = \lim_{n \to \infty} |\frac{a_{n+1}}{a_n}|$
Then:
- If $L>1$, the series diverges (terms are always growing!)
- If $L<1$, then series converges absolutely (Terms are always decreasing (significantly))
- If $L=1$, the test is inconclusive (terms in the limit converge)

usually for factorials and stuff
# Root Test 
Let $\sum a_{n}$ be any infinite series and let $L = \lim_{n \to \infty} \sqrt[n]{|a_{n}|}$
Then 
- If $L>1$, the series diverges 
- If $L<1$, the series is absolutely convergent 
- If $L=1$, the test is inconclusive

for exponential functions or $n^n$
**Root test is a stronger convergent test than the ratio test**
	There are series for which ratio test can be inclusive but the root test yields results but for anything that the ratio test yields results for, the root test works.
	Root test however, is slightly simpler to evaluate. Especially, for factorials! Since factorials cancel out but $\sqrt[n]{n!}$ is pretty bad to converge.
		#funfact Stirling's Estimate 
			$n! \approx \sqrt{2 \pi n} (\frac{n}{e})^{n}$ (asymptotically)
			i.e. you can replace $\lim_{n \to \infty} \sqrt[n]{n!}$ with $\lim_{n \to \infty} \sqrt[n]{\sqrt{2 \pi n} (\frac{n}{e})^{n}} = \lim_{n \to \infty} \frac{\sqrt[n]{\sqrt{2 \pi n}} \frac{n}{e}}{n} = \frac{1}{e}$
				Hence, $\sqrt[n]{n!}$ converges to $\frac{1}{e}$
			

## Why they work 
The idea of the ratio and group test is that 
- If $L \neq 1$ then the series $\sum a_{n}$ behaves like a geometric series in the limit that you get further down the sequence.
	- Here, the common ratio would then be $L$, and you can just apply the ideas of a geometric series.
- The limit being a common ratio in the Ratio test is obvious.
- For the Root test, note how $ar^{n}$, i,e, the $nth$ term of a sequence would yield $\sqrt[n]{ar^{n}} = \sqrt[n]{a} \, r$
	- in the limit as $n \to \infty$, $\sqrt[n]{a} \to 1$ for positive values of $a$ both smaller and larger than 1. Hence, the $\lim_{n \to \infty} \sqrt[n]{ar^{n}} = r = L$

So the idea is all series can be thought of as a geometric series in the limit. I.e. we can think of at least it's final few terms as having a certain common ratio. Looking at what that common ratio can be can hint us towards what the series is doing.

---
#### Example 
$\sum^{\infty}_{n=1} \frac{n^{6}}{2^{n}}$

here, $\lim_{n \to \infty} |\frac{a_{n+1}}{a_{n}}| = \lim_{n \to \infty} |\frac{\frac{(n+1)^6}{2^{n+1}}}{\frac{n^6}{2^n}}|$
$= \lim_{n \to \infty} \frac{1}{2} (\frac{n+1}{n})^{6} = \frac{1}{2}$
Hence, the common ratio of the terms tend to be $\frac{1}{2}$
which means the terms in the limit act as a convergent geometric series. Hence, the series itself converges.

---
#### Few other problems 
$$\sum^{\infty}_{n=1} \frac{(2n)!}{n!n!}$$
$$\implies a_{n} = \frac{(n+1)(n+2)\dots(2n-1)(2n)}{n!}$$
$$\lim_{n \to \infty} \frac{a_{n+1}}{a_{n}}=\lim_{n \to \infty} \frac{\frac{(n+2)(n+3)\dots(2(n+1))}{((n+1))!}}{\frac{(n+1)(n+2)\dots(2n)}{(n)!}}=\lim_{n \to \infty}\frac{(n+2)(n+3)\dots(2n+1)(2n+2)}{(n+1)!}\cdot\frac{(n)!}{(n+1)(n+2)\dots(2n)} =\lim_{n \to \infty} \frac{(2n+2)(2n+1)}{(n+1)(n+1)} = 4$$
Since the common ratio tends to be $4$, the series diverges by the ratio test

#### Example of the Root test 
$\sum^{\infty}_{n=3} \frac{(n+1)(2^{n+1})}{n^{n}}$

Using the Root test, 
$\lim_{n \to \infty} \sqrt[n]{|a_{n}|} = \lim_{n \to \infty} \sqrt[n]{\frac{(n+1)(2^{n+1})}{n^{n}}}$
$= \lim_{n \to \infty} \frac{\sqrt[n]{n+1} \, 2^{1+ \frac{1}{n}}}{n} = \frac{1 \cdot 2}{\infty}= 0$
Since the limiting ratio between terms is zero, the series converges by the root test. (i.e. the sequence drops down drastically and very steeply as $n \to \infty$)


And obvious way to see if something would be inconclusive by the ratio or root test, we can see if the term $a_{n}$ contains any exponentially growing or decaying term or not.

If there is no $exp(n)$ term in $a_{n}$ i.e. $\set{c^{n}, n!, n^{n}}$ are NOT present then the test would be inconclusive since it is obvious the series yields no geometric behavior.

In such cases, comparison tests would be handy for things that do NOT grow with exponential functions.

---
## Alternating Series Test 
#def If $\sum^{\infty}_{n=k} a_{n}$ is a convergent series but NOT and absolutely convergent series, $\sum^{\infty}_{n=k} a_{n}$ is **conditionally convergent**.

I.e. $\sum^{\infty}_{n=k} |a_{n}|$ does NOT converge, and the terms are not getting small enough to converge on their own. But the cancellation interplay between terms gets the series to converge.

#def An **alternating series** is a series whose terms alternate signs.

#### Example 
$1 - \frac{1}{2} + \frac{1}{4} - \frac{1}{8} + \frac{1}{16} \dots$ is an alternating series 
on the other hand,
$1 + \frac{1}{2} - \frac{1}{4} - \frac{1}{8} + \frac{1}{16} + \frac{1}{32} \dots$ is NOT an alternating series. (although signs are changing, they do not change for alternate terms)

>The Hallmark of an Alternating Series is a $(-1)^{n}$ term in an $a_{n}th$ term.

Every Alternating series $\sum a_{n}$ can be written as $\sum (-1)^{n}b_{n}$ (or $\sum (-1)^{n+1}b_{n}$) where $b_{n}>0$ for all $n$, $b_{n} = |a_{n}|$
#### Identifying Alternating Series 
- $\sum^{\infty}_{n=2} \frac{(-1)^{n}}{n^{2}+1}$
Yes, alternating $-ve$ sign

- $\sum^{\infty}_{n=3} \frac{(-1)^{2n+1}}{n}$
$2n+1$ is always positive hence sign does NOT alternate

- $\sum^{\infty}_{n=3} \frac{(-1)^{3n+1}}{n}$
Yes, alternating

- $\sum^{\infty}_{n=4}\frac{cos(\pi n)}{5^{n}}$
Yes, the signs are still alternating since all odd terms give you $-1$ and all even terms give you $1$.

- $\sum^{\infty}_{n=5} \frac{1}{n} + \frac{(-1)^{n}}{n^{2}}$
Since $\frac{(-1)^{n}}{n^{2}}$ gets smaller, overall, for numbers further down, the $\frac{1}{n}$ term dominates and never changes sign.

- $\sum^{\infty}_{n=6} \frac{1}{n} + \frac{(-1)^{n}}{\sqrt{n}}$
Here, since the $\frac{1}{\sqrt{n}}$ term dominates $\frac{1}{n}$ for large enough $n$, $\frac{(-1)^{n}}{\sqrt{n}}$ dominates the behavior hence, the signs alternate.

---
#theorem Alternating Series Test 
Suppose we have an alternating series written as $\sum^{\infty}_{n=k} (-1)^{n}b_{n}$ (with $b_{n}>0$) and suppose that $b_{n}$ is a ~~(strictly)~~ decreasing sequence & $\lim_{n \to \infty} b_{n} = 0$
Then $\sum_{n=k}^{\infty} (-1)^{n}b_{n}$ converges.

But WHY?
### The Proof for AST 
(Proof by picture)
Let's Visualize $S_{n} = \sum^{N}_{n=1} (-1)^{n}b_{n}$ 
![[Maths/Calc 2/attachments/Drawing 24-11-04-06-07-08]]

$[S_{2}, S_{1}] > [S_{4}, S_{5}] > [S_{6}, S_{5}]$

Notice how $S_{2n}-S_{2n-1} = b_{2n}$
since $\lim_{n \to \infty} b_{n} = 0$, length of intervals go to $0$ .

There is a sequence of real number $L$ such that $L$ is in all the intervals $\implies S_{n} = L$

I.e. The sum $S_{n}$ of the series is contained within the previous interval since the amount you move is always less than the previous series.

In the limit, since the intervals get smaller and smaller and $S_{n}$ must be included in all the intervals, the limiting value of the sum $S_{n}$ MUST be the limiting value that the interval converges to.

As several other tests, this does NOT show WHAT value does the sequence converge to. This only proves that it is bound between finite numbers.

---
#### Example 
- $\sum^{\infty}_{n=1} \frac{(-1)^{n}}{n}$ (the alternating harmonic series)

This converges since it is an alternating series with $b_{n} = \frac{1}{n}$ which is a decreasing function with $\lim_{n \to \infty} b_{n} = 0$

- $\sum^{\infty}_{n=3} \frac{(-1)^{n}n^{2}}{n^{3}+1}$

Here, $b_{n}= \frac{n^{2}}{n^{3}+1}$ which is decreasing ($\frac{p_{2}}{p_{3}}$ has a denominator growing always faster than the numerator) and approaches $0$. Hence, by the alternate series test, this converges.

- $\sum^{\infty}_{n=1} \frac{(-1)^{n} n^{n}}{n!}$

Here, $b_{n} = \frac{n^{n}}{n!}$ since $n^{n}$ grows faster than $n!$, the limit booms off to infinity.
So by only the divergence test alone, you can tell the terms themselves do not converge and in fact diverge to infinity. If either of the terms is $\infty$, the series diverges.

- $\sum^{\infty}_{n=8} \frac{(-1)^{n+1}(n^{2} + 3n + 2)}{n^{4}+5n +1}$
Here, obviously $b_{n}$ decreases and converges to $0$. Hence, the series also converges.

You could also realize that the series of the absolute value of the terms itself converges (it's close enough to $\frac{1}{n^{2}}$ in the long run (you can precisely prove than by Limit Comparison test with $\frac{1}{n^{2}}$)), then using the absolute convergence test, the series also converges.

So If you see alternate $-1$s, You can see if the series' absolute value converges or not, you consider the behavior of the absolute value of the terms themselves.

If the series of the absolute terms converges, then the alternating series converges absolutely.
If instead the absolute terms themselves converge (which would be true if the series converges), then the alternating series is conditionally convergent.

Either ways, you just need to check if the absolute terms converge. But to make the distinction of absolute and conditional, you need to also check if the series itself converges.

---
### Approximation for Alternative Series 
For alternating series, there's an easy way to estimate how close a partial sum is to the value of the series.

#### Alternating Series Error Estimating Theorem
#theorem Let $\sum^{\infty}_{n=1} (-1)^{n}b_{n}$ be an alternating series satisfying the AST. Let $L = \sum^{\infty}_{n=1} (-1)^{n}b_{n}$ and $S_{N} = \sum^{N}_{n=1}(-1)^{n}b_{n}$ then $|L-S_{N}|<b_{N+1}$

###### Example 
- Use ASEET to get an upper bound for using the first 10 terms of $\sum^{\infty}_{n=1} \frac{(-1)^{n}}{n^{2}+1}$ to estimate the series.
$|L - S_{10}| < b_{11} = \frac{1}{11^{2}+1} = \frac{1}{122}$
Hence, the 11th partial sum is AT MOST $\frac{1}{122}$ away from the actual value of that series.

Essentially, $b_{n+1}$ is the upper bound for the error for $S_{n}$ from the actual value of the series.


- For instance, for $\sum^{\infty}_{n=1} \frac{(-1)^{n}}{\sqrt[3]{n}}$,
$S_{999}$ would have an error bound of $\frac{1}{\sqrt[3]{1000}}= \frac{1}{10}$
Now, seeing that, adding 999 terms, you only expect the bound to be $10\%$ error seems pretty loose. In reality, you're gonna be MUCHH closer to the actual sum by that point.

So ASEET is not the most efficient way to approximate error. However, it is a reliable way!


- Find the minimum number of terms you need to use so that ASEET guarantees $|L-S_{N}|<1000$, for $\sum^{\infty}_{n=1} \frac{(-1)^{n}}{n^{2}+1}$

So you want $\frac{1}{n^{2}+1} < \frac{1}{1000}$ for integer $n$ $\implies n^{2}> 1000-1 \implies n > \sqrt{999} \implies n > 31.something$
$\implies n = 32$
Hence, $S_{n-1}$ would be the first sum to have an error bound of at most $\frac{1}{1000}$.
Hence, the sum would be $S_{31}$

**Attention! The Error in $S_{n}$ is $b_{n+1}$ hence, to find a bound, you equate $n+1$ not $n$. So the number of terms in the Sum will be 1 less!**

---
$S = 1 - \frac{1}{2} + \frac{1}{3} - \frac{1}{4} + \frac{1}{5} \dots$
$2S = 2 - 1 + \frac{2}{3} - \frac{1}{2} + \frac{2}{5} - \frac{1}{3} + \frac{2}{7} - \frac{1}{4} + \frac{2}{9}$
collecting common terms,
$2S = 1 - \frac{1}{2} + \frac{1}{3} - \frac{1}{4} + \frac{1}{5} \dots$
But that is what we started with!

$\implies 2S = S$
$\implies 2 = 1$ !!! What!

#theorem Riemann Rearrangement Theorem
Let $\sum^{\infty}_{n=1} a_{n}$ is a conditionally convergent series.
Then,
- The sum of the positive terms of $a_{n}$ diverges.
- The sum of the negative terms of $a_{n}$ diverges.
- **For any real number $S$ (including $\infty, -\infty$), the terms of the series can be rearranged so that the series converges to $S$**
> For conditionally convergent series, order of addition matters. But depending on how you reorder them, you can make the series to converge to any number you like.

So conditionally converging series are cooked! Weird! Funky! Unusual! Puzzling!

That is how Ramanujan got away with that.
Essentially, $\infty - \infty$ is an indeterminant form and can take any shape you want to craft it to.


